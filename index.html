<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="description" content="SG-RAPL: Scene Graph-Driven Reasoning for Action Planning of Humanoid Robot">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SG-RAPL: Scene Graph-Driven Reasoning for Action Planning</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
<section class="authors">
  <div class="authors-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">SG-RAPL: Scene Graph-Driven Reasoning for Action Planning of Humanoid Robot</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">D.A. Yudin</a><sup>1,2*</sup>,</span>
            <span class="author-block">A.A. Kochetkova</a><sup>1</sup>,</span>
            <span class="author-block">A.A. Lazarev<sup>1</sup>,</span>
            <span class="author-block">E.A. Bakaeva<sup>1</sup>,</span>
            <span class="author-block">A.K. Kovalev<sup>2</sup>,</span>
            <span class="author-block">A.I. Panov<sup>2</sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <sup>1</sup><span class="author-block">Moscow Institute of Physics and Technology</span>, 
            <sup>2</sup><span class="author-block">AIRI, Moscow</span>
          </div>
          <div class="is-size-6 publication-authors">
            <sup>*</sup><span class="author-block">Corresponding author: yudin.da@mipt.ru</span>
          </div>
          <div class="publication-links">
            <span class="link-block">
              <a href="https://arxiv.org/abs/2505.XXXX" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="ai ai-arxiv"></i></span><span>arXiv</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://github.com/yourusername/SG-RAPL" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fab fa-github"></i></span><span>Code</span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="abstract">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          Recent advances in mapping and depth prediction have enabled autonomous robots to interpret tasks in natural language. SG-RAPL presents a high-level planning algorithm for dynamic environments, using a scene graph to detail the world and flag abnormal situations. Large language models transform natural-language tasks into linear temporal logic automata for effective replanning. A perceptual segmentation and tracking module generates a real-time трехмерное scene graph with instance segmentation, obstacle detection, and 6DoF-pose estimation. The scheduler decomposes tasks into navigation and manipulation subtasks. Experiments in virtual environments demonstrate efficient complex task scheduling, advancing adaptive humanoid robots for healthcare, logistics, and manufacturing.
        </div>
      </div>
    </div>
  </div>
</section>

<section class="News">
  <div class="container is-max-desktop">
    <h2 class="title is-3">News</h2>
    <p class="has-text-centered">[2025.05] Accepted to Applied Soft Computing (in press).</p>
  </div>
</section>

<section class="Demo">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Demo Pipeline</h2>
    <p class="has-text-centered">The live demonstration shows perception, scene graph construction, command input, and planner output.</p>
    <img src="./static/images/demo_pipeline_screenshot.png" alt="Demo Pipeline Screenshot" style="width:100%; height:auto; display:block; margin:0 auto;">
  </div>
</section>

<section class="Method">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Method</h2>
    <div class="content has-text-justified">
      <p>SG-RAPL integrates two nodes: Perception and Planner. The Perception Module generates a трехмерное scene graph from RGB images and ArUco-based depth calibration. The Planner uses few-shot LLM prompting to decompose user commands into linear temporal logic automata and outputs actionable sequences. An Actual State Service maintains environment state for replanning.</p>
      <img src="./static/images/sg_rapl_arch.png" alt="Architecture Diagram" style="width:100%; height:auto; display:block; margin:0 auto;">
    </div>
  </div>
</section>

<section class="Results">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Results</h2>
    <h4 class="title is-4">Instance Segmentation</h4>
    <img src="./static/images/segmentation_results.png" alt="Segmentation Results" style="width:100%; height:auto; display:block; margin:0 auto;">
    <h4 class="title is-4">Planning Performance</h4>
    <img src="./static/images/planning_metrics.png" alt="Planning Metrics" style="width:100%; height:auto; display:block; margin:0 auto;">
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{yudin2025sgraph,
  title={SG-RAPL: Scene Graph-Driven Reasoning for Action Planning of Humanoid Robot},
  author={Yudin, Dmitry A. and Kochetkova, Anna A. and Lazarev, Alexey A. and Bakaeva, Ekaterina A. and Kovalev, Andrey K. and Panov, Alexey I.},
  journal={Applied Soft Computing},
  year={2025},
  note={Preprint available at \url{https://arxiv.org/abs/2505.XXXX}}
}
</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>This site is licensed under Creative Commons Attribution-ShareAlike 4.0 International License.</p>
    </div>
  </div>
</footer>

</body>

</html>
