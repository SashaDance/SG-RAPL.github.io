<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="description" content="SG-RAPL: Scene Graph-Driven Reasoning for Action Planning of Humanoid Robot">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SG-RAPL: Scene Graph-Driven Reasoning for Action Planning</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
<section class="authors">
  <div class="authors-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">SG-RAPL: Scene Graph-Driven Reasoning for Action Planning of Humanoid Robot</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">D.A. Yudin</a><sup>1,2*</sup>,</span>
            <span class="author-block">A.A. Kochetkova</a><sup>1</sup>,</span>
            <span class="author-block">A.A. Lazarev<sup>1</sup>,</span>
            <span class="author-block">E.A. Bakaeva<sup>1</sup>,</span>
            <span class="author-block">A.K. Kovalev<sup>1,2</sup>,</span>
            <span class="author-block">A.I. Panov<sup>1,2</sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <sup>1</sup><span class="author-block">Moscow Institute of Physics and Technology</span>, 
            <sup>2</sup><span class="author-block">AIRI, Moscow</span>
          </div>
          <div class="is-size-6 publication-authors">
            <sup>*</sup><span class="author-block">Corresponding author: yudin.da@mipt.ru</span>
          </div>
          <div class="publication-links">
            <!-- <span class="link-block">
              <a href="https://arxiv.org/abs/2505.XXXX" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="ai ai-arxiv"></i></span><span>arXiv</span>
              </a>
            </span> -->
            <span class="link-block">
              <a href="https://github.com/SashaDance/SG-RAPL" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fab fa-github"></i></span><span>Code</span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="abstract">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
            Recent advances in mapping and depth prediction have enabled autonomousrobots to interpret tasks in natural language. This paper presents a high-level planning algorithm for dynamic environments, allowing adaptive andoptimal control of anthropomorphic robots. Using a scene graph to detail theworld map and indicate abnormal situations, large language models trans-form natural language tasks into linear temporal logic automata for effectivere-planning. A perceptual segmentation and tracking module generates areal-time 3D scene graph, providing instance segmentation, obstacle detec-tion, and 6DoF-pose detection. The scheduling module decomposes high-level tasks into subtasks like navigation and object manipulation. Exper-iments show the approach enables efficient scheduling of complex tasks invirtual environments. This work advances autonomous, adaptable robots forapplications in healthcare, logistics, and manufacturing.
        </div>
      </div>
    </div>
  </div>
</section>

<section class="Method">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Method</h2>
    <div class="content has-text-justified">
      <p>The project contains two main nodes: Planner and Perception Module. The purple block represents all data coming from outside the pipeline for further processing. The arrows show the interaction of different modules and the addition of negative feedback from the environment and the robot. The Scheduler generates control instructions for the robot based on the json file generated by the Perception module. Analysis by visual information works in service mode and transmits a message to the Planner Module on request when one of five check points is reached.</p>
      <img src="./static/media/robograph_scheme.png" alt="SG-RAPL Scheme" style="width:100%; height:auto; display:block; margin:0 auto;">
    </div>
  </div>
</section>

<section class="Demo">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Demo Pipeline</h2>
    <p class="has-text-centered">
      The Perception Module first processes the RBG frame, Actual State service updates environment information which used by Planner Module to decompose user text command.
    </p>
    <video autoplay loop muted playsinline controls style="width:100%; height:auto; display:block; margin:0 auto;">
      <source src="./static/media/demo.webm" type="video/webm">
      Your browser does not support the video tag.
    </video>
  </div>
</section>

<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{yudin2025sgraph,
  title={SG-RAPL: Scene Graph-Driven Reasoning for Action Planning of Humanoid Robot},
  author={Yudin, Dmitry A. and Kochetkova, Anna A. and Lazarev, Alexey A. and Bakaeva, Ekaterina A. and Kovalev, Andrey K. and Panov, Alexey I.},
  journal={Applied Soft Computing},
  year={2025},
  note={Preprint available at \url{https://arxiv.org/abs/2505.XXXX}}
}
</code></pre>
  </div>
</section> -->

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>This site is licensed under Creative Commons Attribution-ShareAlike 4.0 International License.</p>
    </div>
  </div>
</footer>

</body>

</html>
